{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOg_ak9E_CTQ"
      },
      "source": [
        "# ðŸ“ž Call Quality Analyzer â€” Final (Colab Ready)\n",
        "\n",
        "This notebook analyzes a **sales call recording** and outputs:\n",
        "1. Talk-time ratio (% each person spoke)\n",
        "2. Number of questions asked\n",
        "3. Longest monologue duration\n",
        "4. Call sentiment (positive/negative/neutral)\n",
        "5. One actionable insight\n",
        "\n",
        "**Bonus:** Attempts to identify Sales Rep vs Customer.\n",
        "\n",
        "---\n",
        "### How to run\n",
        "1. Open in Colab\n",
        "2. Runtime â†’ Change runtime type â†’ GPU\n",
        "3. Runtime â†’ Run all\n",
        "4. Final results will also be saved in `call_report.txt` (downloadable)\n"
      ],
      "id": "zOg_ak9E_CTQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXXOLLFO_CTV",
        "outputId": "74746272-5992-4f27-baa7-09f3c01e8d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q yt-dlp pytube faster-whisper transformers torch pydub librosa soundfile\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg\n",
        "print('âœ… Installed all dependencies')"
      ],
      "id": "lXXOLLFO_CTV",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "âœ… Installed all dependencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40B6XSSg_CTW",
        "outputId": "80c21478-0ce7-4b58-d758-2d0d8bf71b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 2: Imports and helpers\n",
        "import os, re\n",
        "from pytube import YouTube\n",
        "from pydub import AudioSegment, effects\n",
        "from faster_whisper import WhisperModel\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('Device:', device)\n",
        "\n",
        "# Robust downloader: pytube first, yt-dlp fallback\n",
        "def download_audio(youtube_url, out_path=\"call_audio.mp3\"):\n",
        "    try:\n",
        "        print(\"ðŸŽ¬ Trying pytube...\")\n",
        "        yt = YouTube(youtube_url)\n",
        "        stream = yt.streams.filter(only_audio=True).order_by(\"abr\").desc().first()\n",
        "        stream.download(filename=out_path)\n",
        "        print(\"âœ… Downloaded with pytube\")\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ Pytube failed:\", e)\n",
        "        print(\"ðŸŽ¬ Trying yt-dlp instead...\")\n",
        "        import yt_dlp\n",
        "        ydl_opts = {\n",
        "            \"format\": \"bestaudio/best\",\n",
        "            \"outtmpl\": out_path,\n",
        "            \"postprocessors\": [{\n",
        "                \"key\": \"FFmpegExtractAudio\",\n",
        "                \"preferredcodec\": \"mp3\",\n",
        "                \"preferredquality\": \"192\",\n",
        "            }],\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "        print(\"âœ… Downloaded with yt-dlp\")\n",
        "    return out_path\n",
        "\n",
        "# Helper: normalize audio\n",
        "def to_wav_mono_16k(src, dst='call_audio.wav'):\n",
        "    audio = AudioSegment.from_file(src)\n",
        "    audio = effects.normalize(audio)\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "    audio.export(dst, format='wav')\n",
        "    return dst\n",
        "\n",
        "print('âœ… Helpers ready')"
      ],
      "id": "40B6XSSg_CTW",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "âœ… Helpers ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m97lV9dS_CTX",
        "outputId": "ba717e7e-bd1e-4556-bfae-15cff9e70027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 3: Download or Upload audio\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=4ostqJD3Psc\"\n",
        "AUDIO_MP3 = \"call_audio.mp3\"\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(AUDIO_MP3):\n",
        "        download_audio(YOUTUBE_URL, out_path=AUDIO_MP3)\n",
        "\n",
        "        # âœ… Fix: handle yt-dlp double extension\n",
        "        if os.path.exists(\"call_audio.mp3.mp3\"):\n",
        "            os.rename(\"call_audio.mp3.mp3\", \"call_audio.mp3\")\n",
        "            print(\"Renamed double-extension file to call_audio.mp3\")\n",
        "    else:\n",
        "        print(\"Audio already downloaded\")\n",
        "except Exception as e:\n",
        "    print(\"âš ï¸ Download failed:\", e)\n",
        "    from google.colab import files\n",
        "    print(\"Please upload call_audio.mp3 manually\")\n",
        "    uploaded = files.upload()\n",
        "    AUDIO_MP3 = list(uploaded.keys())[0]\n",
        "\n",
        "print(\"File exists?\", os.path.exists(AUDIO_MP3))\n"
      ],
      "id": "m97lV9dS_CTX",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio already downloaded\n",
            "File exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcsnGdL__CTX",
        "outputId": "e8139d46-0d8e-447b-f3a8-409bfb24568d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 4: Transcribe audio\n",
        "model = WhisperModel(\"tiny\", device=device)\n",
        "segments, info = model.transcribe(AUDIO_MP3, beam_size=5)\n",
        "\n",
        "transcript = []\n",
        "for seg in segments:\n",
        "    transcript.append({\n",
        "        \"start\": seg.start,\n",
        "        \"end\": seg.end,\n",
        "        \"dur\": seg.end - seg.start,\n",
        "        \"text\": seg.text.strip()\n",
        "    })\n",
        "\n",
        "print(\"âœ… Transcript ready\")\n",
        "print(\"Sample:\", transcript[:3])"
      ],
      "id": "wcsnGdL__CTX",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Transcript ready\n",
            "Sample: [{'start': 0.0, 'end': 11.4, 'dur': 11.4, 'text': 'Thank you for calling me son. My name is Lauren. Can I have your name?'}, {'start': 11.4, 'end': 16.2, 'dur': 4.799999999999999, 'text': 'Yes, my name is John Smith. Thank you, John. How can I help you?'}, {'start': 16.2, 'end': 20.6, 'dur': 4.400000000000002, 'text': 'I was just calling about to see how much it would cost to update the map in my car.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS9pHBSM_CTX",
        "outputId": "ee052f3d-e460-4ae6-cc01-a9dade8f938b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 5: Analysis\n",
        "speaker_durations = {'Speaker_1':0.0, 'Speaker_2':0.0}\n",
        "speaker_segments = {'Speaker_1':[], 'Speaker_2':[]}\n",
        "\n",
        "for i, s in enumerate(transcript):\n",
        "    sp = 'Speaker_1' if i%2==0 else 'Speaker_2'\n",
        "    speaker_durations[sp] += s['dur']\n",
        "    speaker_segments[sp].append(s)\n",
        "\n",
        "total_speech_time = sum(speaker_durations.values()) or 1.0\n",
        "talk_ratio = {k: round(100*v/total_speech_time,1) for k,v in speaker_durations.items()}\n",
        "\n",
        "# Questions detection\n",
        "qcount = 0\n",
        "for s in transcript:\n",
        "    text = s['text']\n",
        "    if '?' in text:\n",
        "        qcount += text.count('?')\n",
        "    elif re.search(r\"\\b(what|why|how|when|where|who|is|are|do|did|can|could|would|should)\\b\", text.lower()):\n",
        "        qcount += 1\n",
        "\n",
        "# Longest monologue\n",
        "long_A = max([seg['dur'] for seg in speaker_segments['Speaker_1']] or [0])\n",
        "long_B = max([seg['dur'] for seg in speaker_segments['Speaker_2']] or [0])\n",
        "longest = max(long_A, long_B)\n",
        "longest_speaker = 'Speaker_1' if long_A>=long_B else 'Speaker_2'\n",
        "\n",
        "# Sentiment\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "joined_text = ' '.join([s['text'] for s in transcript])[:1000]\n",
        "sent_res = classifier(joined_text)\n",
        "\n",
        "# Insight\n",
        "if talk_ratio['Speaker_1'] > 70 or talk_ratio['Speaker_2'] > 70:\n",
        "    dom = 'Speaker_1' if talk_ratio['Speaker_1']>talk_ratio['Speaker_2'] else 'Speaker_2'\n",
        "    insight = f\"{dom} dominates the call ({talk_ratio[dom]}%). Suggest: ask more questions and pause to listen.\"\n",
        "elif qcount < 3:\n",
        "    insight = 'Too few questions asked. Encourage asking more open-ended questions.'\n",
        "else:\n",
        "    insight = 'Balanced speaking. Maintain clarifying questions.'\n",
        "\n",
        "# Likely Sales Rep\n",
        "sales_rep = 'Speaker_1' if talk_ratio['Speaker_1']>talk_ratio['Speaker_2'] else 'Speaker_2'\n",
        "\n",
        "print('\\n===== CALL QUALITY REPORT =====')\n",
        "print('Talk-time ratio (%):', talk_ratio)\n",
        "print('Number of questions:', qcount)\n",
        "print('Longest monologue (s):', longest, 'by', longest_speaker)\n",
        "print('Call sentiment:', sent_res)\n",
        "print('Actionable insight:', insight)\n",
        "print('Likely Sales Rep:', sales_rep)"
      ],
      "id": "LS9pHBSM_CTX",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CALL QUALITY REPORT =====\n",
            "Talk-time ratio (%): {'Speaker_1': 55.1, 'Speaker_2': 44.9}\n",
            "Number of questions: 15\n",
            "Longest monologue (s): 11.4 by Speaker_1\n",
            "Call sentiment: [{'label': 'POSITIVE', 'score': 0.9278588891029358}]\n",
            "Actionable insight: Balanced speaking. Maintain clarifying questions.\n",
            "Likely Sales Rep: Speaker_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2HvsQ4C_CTX",
        "outputId": "1ff50a77-52f5-40a9-aa74-ac37182d8091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Step 6: Save report to txt\n",
        "report_lines = []\n",
        "report_lines.append('ðŸ“ž Call Quality Report')\n",
        "report_lines.append('-'*40)\n",
        "report_lines.append(f'Talk-time ratio: {talk_ratio}')\n",
        "report_lines.append(f'Number of questions asked: {qcount}')\n",
        "report_lines.append(f'Longest monologue duration: {longest:.1f} seconds (by {longest_speaker})')\n",
        "report_lines.append(f'Overall sentiment: {sent_res[0][\"label\"]} ({sent_res[0][\"score\"]:.2f})')\n",
        "report_lines.append(f'Actionable insight: {insight}')\n",
        "report_lines.append(f'Likely Sales Rep: {sales_rep}')\n",
        "\n",
        "with open('call_report.txt','w') as f:\n",
        "    f.write('\\n'.join(report_lines))\n",
        "\n",
        "print('\\nâœ… Report saved as call_report.txt')\n",
        "print(\"Download with: from google.colab import files; files.download('call_report.txt')\")"
      ],
      "id": "D2HvsQ4C_CTX",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Report saved as call_report.txt\n",
            "Download with: from google.colab import files; files.download('call_report.txt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jabk3sv_CTX"
      },
      "source": [
        "## ðŸ“Œ Explanation (under 200 words)\n",
        "\n",
        "We download the call audio using pytube (fallback yt-dlp if needed), normalize and convert to 16kHz mono. We transcribe with **faster-whisper (tiny)** for speed on Colab free tier. Segments are alternately assigned to Speaker 1 and 2 (approximate diarization).\n",
        "- **Talk-time ratio**: computed from speech durations.\n",
        "- **Questions**: detected by '?' and WH-words.\n",
        "- **Longest monologue**: max continuous speech span.\n",
        "- **Sentiment**: HuggingFace pipeline.\n",
        "- **Insight**: simple rules for dominance or low questions.\n",
        "- **Bonus**: sales rep guessed as dominant speaker.\n",
        "\n",
        "Finally, results are saved in `call_report.txt` for easy download. This design ensures <30s runtime and explainability.\n"
      ],
      "id": "-jabk3sv_CTX"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}